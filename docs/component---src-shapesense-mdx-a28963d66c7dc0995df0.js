(window.webpackJsonp=window.webpackJsonp||[]).push([[8],{PJ5t:function(e,t,n){"use strict";n.r(t),n.d(t,"_frontmatter",(function(){return l})),n.d(t,"default",(function(){return h}));var i=n("Fcif"),a=n("+I+c"),o=(n("mXGw"),n("/FXl")),s=n("TjRS"),r=n("zmid"),l=(n("aD51"),{});void 0!==l&&l&&l===Object(l)&&Object.isExtensible(l)&&!l.hasOwnProperty("__filemeta")&&Object.defineProperty(l,"__filemeta",{configurable:!0,value:{name:"_frontmatter",filename:"src/shapesense.mdx"}});var c=s.a;function h(e){var t=e.components,n=Object(a.a)(e,["components"]);return Object(o.b)(c,Object(i.a)({},n,{components:t,mdxType:"MDXLayout"}),Object(o.b)("h1",{id:"shapesense---shape-completion-by-curve-stitching"},"ShapeSense - Shape Completion by Curve Stitching"),Object(o.b)("p",null,"Researcher: ",Object(o.b)("a",{href:"//github.com/shpun817",parentName:"p"},"Sanford Pun")," | Supervisor: ",Object(o.b)("a",{href:"//github.com/tyt2y3",parentName:"p"},"Chris Tsang")," | Published: 2022-01-02"),Object(o.b)("hr",null),Object(o.b)("p",null,"Repository: ",Object(o.b)("a",{href:"https://github.com/visioncortex/ShapeSense",parentName:"p"},"visioncortex/ShapeSense")),Object(o.b)("p",null,"This project aims at recovering (completing) the ",Object(o.b)("strong",{parentName:"p"},"structure"),' of a shape after a portion of it is erased. In other words, given a shape with arbitrarily "discontinued parts", assuming that we have ',Object(o.b)("strong",{parentName:"p"},"no prior knowledge")," about the shape, how can we ",Object(o.b)("strong",{parentName:"p"},"reasonably connect the endpoints")," at the discontinuities?"),Object(o.b)(r.a,{src:"shape-sense/hole_showcase.png",text:"A shape with a hole. There are 6 endpoints in this case.",alt:"Hole showcase",mdxType:"Figure"}),Object(o.b)("p",null,"In the demo images shown throughout this documentation, the following coloring scheme is used: Black pixels denote the background. Red pixels denote the rasterized ",Object(o.b)("em",{parentName:"p"},"shape"),". White pixels denote the ",Object(o.b)("em",{parentName:"p"},"hole"),'. The (imaginary) intersection of the shape and the hole is the aforementioned "discontinued parts", which is what we try to recover.'),Object(o.b)(r.a,{src:"shape-sense/recovered_shape.png",text:"An example of completed shape.",alt:"Recovered shape showcase.",mdxType:"Figure"}),Object(o.b)("p",null,"Blue pixels will be used to denote the outline of the recovered parts of the shape."),Object(o.b)("p",null,"The whole process of shape completion involves intrapolating the missing outline and then filling the pixels in the hole with appropriate colors."),Object(o.b)("h2",{id:"simple-shape-completion"},"Simple Shape Completion"),Object(o.b)("p",null,"Let's begin the experiment with simple shapes, like an ellipse."),Object(o.b)(r.a,{src:"shape-sense/simple/ellipse_groundtruth_and_with_hole.png",text:"The first image is the ground truth (for reference only). The second image is the input to the ShapeCompletion pipeline.",alt:"An ellipse ground truth and another one with a hole.",mdxType:"Figure"}),Object(o.b)("h3",{id:"path-preprocessing"},"Path Preprocessing"),Object(o.b)("p",null,"The first stage of the pipeline is to obtain and process the paths (curves) representing the existing outline of the shape."),Object(o.b)("p",null,Object(o.b)("a",{href:"//github.com/visioncortex/visioncortex",parentName:"p"},"Vision Cortex's core library")," provides the necessary utilities to extract raw paths from an image."),Object(o.b)(r.a,{src:"shape-sense/simple/ellipse_preprocessed_path.png",text:"Yellow pixels denote the identified outline of the shape after simplification.",alt:"Path segments after preprocessing.",mdxType:"Figure"}),Object(o.b)("h3",{id:"tail-tangent-approximation"},"Tail Tangent Approximation"),Object(o.b)("p",null,"The next step is to (divide, if needed, and) extract the two curves from the two endpoints; smoothing is performed to better approximate the tangents near the endpoints (",Object(o.b)("em",{parentName:"p"},"tails")," of the whole curve). After this step, we will obtain two tangents (2-D direction vectors), one at each tail. We will call these tangents ",Object(o.b)("em",{parentName:"p"},"tail tangents"),"."),Object(o.b)(r.a,{src:"shape-sense/simple/tail_tangent_approx.png",text:"The naive approach is to simply take A as the tail tangent, but better (more practical/useful) approximations may be obtained by taking more subsequent segments into account (e.g. B, C, D).",alt:"Tail tangent approximation results.",mdxType:"Figure"}),Object(o.b)("p",null,"A number of factors determine the accuracy and robustness of tail tangent approximation. Our implementation supports configurations like how many points to consider from the tails, how long should the segments being considered accumulate to, and how the weights for each segment should change towards the tails."),Object(o.b)("h3",{id:"intrapolation"},"Intrapolation"),Object(o.b)("blockquote",null,Object(o.b)("p",{parentName:"blockquote"},Object(o.b)("strong",null,'Why "',Object(o.b)("b",null,"Intra"),'polation"?'),Object(o.b)("br",null),"\nIf we considered the existing outline of the shape as separate curves at each endpoint, we would be doing ",Object(o.b)("i",null,Object(o.b)("b",null,"inter"),"polation")," ",Object(o.b)("b",null,"between")," curves. However, in this project, we are focusing on curves (existing + missing) that form an outline of a single shape, so we argue that we are doing ",Object(o.b)("i",null,Object(o.b)("b",null,"intra"),"polation")," ",Object(o.b)("b",null,"within")," a curve.")),Object(o.b)("p",null,"With the two endpoints and their corresponding tail tangents, we can calculate for the missing part in different scenarios. The type of curves used in this project is cubic ",Object(o.b)("a",{href:"//en.wikipedia.org/wiki/B%C3%A9zier_curve",parentName:"p"},"Bézier curves"),". To specify such a curve, four points are required. An important property to note about this type of curves is that ",Object(o.b)("em",{parentName:"p"},"the curve constructed is always fully contained in the quadrilateral defined by the four points"),"."),Object(o.b)("p",null,"The first scenario is when the two tail tangents point to the same side with respect to the line connecting the two endpoints (we call this line the ",Object(o.b)("em",{parentName:"p"},"base"),")."),Object(o.b)(r.a,{src:"shape-sense/simple/intrapolate_same_side.png",text:"Both tail tangents at A and B point to the same side of the red, dashed line (the base).",alt:"Intrapolation when both tail tangents point to the same side",mdxType:"Figure"}),Object(o.b)("div",null,Object(o.b)("p",null,"To construct the curve between A and B, we need to identify two ",Object(o.b)("em",{parentName:"p"},"control points")," (C",Object(o.b)("sub",null,"A")," and C",Object(o.b)("sub",null,"B"),") between them. In our approach, we started with what we think is intuitive and made tweaks to resolve some issues in practice; this is what we end up with:")),Object(o.b)("br",null),Object(o.b)("div",null,Object(o.b)("p",null,"First, find the intersection of the two lines starting at A and B along the corresponding tail tangent. The mid-points between A/B and the intersection are then set to be C",Object(o.b)("sub",null,"A")," and C",Object(o.b)("sub",null,"B"),". If the intersection is too far away (i.e. the two lines are close to, if not exactly, parallel), we simply use a point on each line as the control points (e.g. translate A/B along their tail tangent by a factor of base length). Either way, if either C",Object(o.b)("sub",null,"A")," or C",Object(o.b)("sub",null,"B")," end up lying outside the hole region, we ",Object(o.b)("em",{parentName:"p"},"retract")," it by pushing it towards the endpoint, until it reaches the hole region.")),Object(o.b)("blockquote",null,Object(o.b)("p",{parentName:"blockquote"},Object(o.b)("strong",null,"What if the intersection was in the other direction?"),Object(o.b)("br",null),"\n",Object(o.b)(r.a,{src:"shape-sense/simple/intrapolation_bent_outwards.png",text:"If the line originating from A and B intersect in the negative direction (as shown above), we simply correct them by bending them inwards to be perpendicular with the base.",alt:"Tail tangents bent outwards; pulled back to be perpendicular to the base.",mdxType:"Figure"}))),Object(o.b)("p",null,"Another scenario is when the two tail tangents point to different sides of the base, as below."),Object(o.b)(r.a,{src:"shape-sense/simple/intrapolate_diff_sides.png",text:"A simple dot product operation can be used to detect such a scenario.",alt:"Intrapolation with tail tangents pointing to different sides of the base",mdxType:"Figure"}),Object(o.b)("p",null,"In this case, any intersections detected are meaningless because they must lie outside the hole region. Instead, we divide the curve into two halves and intrapolate two subcurves from each endpoint to the mid-point of the base as shown above."),Object(o.b)("p",null,"The last possible scenario is trivial to handle: when the lines are coincident, simply connect the endpoints with a straight line."),Object(o.b)(r.a,{src:"shape-sense/simple/intrapolate_coincidence.png",alt:"Intrapolation becomes connecting endpoints with a straight line in coincidence",mdxType:"Figure"}),Object(o.b)("p",null,"The case of our simple ellipse falls into the first scenario. The intrapolated outline is shown as follows:"),Object(o.b)(r.a,{src:"shape-sense/simple/ellipse_intrapolated.png",alt:"Full ellipse outline after intrapolation.",mdxType:"Figure"}),Object(o.b)("h3",{id:"color-filling"},"Color filling"),Object(o.b)("p",null,"To fill the hole with appropriate colors, we define three element types: ",Object(o.b)("em",{parentName:"p"},"Blank"),", ",Object(o.b)("em",{parentName:"p"},"Structure"),", and ",Object(o.b)("em",{parentName:"p"},"Texture"),". Note that in this project, it is restricted that only one shape is processed at once, and actual texture recovery is not performed - we're only interested in knowing which parts of the hole are Blank, Structure, or Texture."),Object(o.b)("table",null,Object(o.b)("thead",{parentName:"table"},Object(o.b)("tr",{parentName:"thead"},Object(o.b)("th",{align:"left",parentName:"tr"},"Element"),Object(o.b)("th",{align:"left",parentName:"tr"},"Description"))),Object(o.b)("tbody",{parentName:"table"},Object(o.b)("tr",{parentName:"tbody"},Object(o.b)("td",{align:"left",parentName:"tr"},"Blank"),Object(o.b)("td",{align:"left",parentName:"tr"},"Background pixels. (Black in our demo)")),Object(o.b)("tr",{parentName:"tbody"},Object(o.b)("td",{align:"left",parentName:"tr"},"Structure"),Object(o.b)("td",{align:"left",parentName:"tr"},"Outline of the shape; The intrapolated curve(s) obtained above is rasterized and drawn onto the hole. (Blue in our demo)")),Object(o.b)("tr",{parentName:"tbody"},Object(o.b)("td",{align:"left",parentName:"tr"},"Texture"),Object(o.b)("td",{align:"left",parentName:"tr"},"Solid part of the shape; To be filled in this section. (Red in our demo)")))),Object(o.b)("p",null,"The Structure elements divide the hole into several subregions. Each of these subregions contains wholly either Blank or Texture elements."),Object(o.b)(r.a,{src:"shape-sense/simple/filling_subregions.png",alt:"Hole of ellipse divided into two subregions",mdxType:"Figure"}),Object(o.b)("p",null,"In our example, the hole is divided by the intrapolated curve into two subregions. In order to guess whether to fill the subregions with Blank or Texture elements, we check if the number of Blank elements outside the hole boundary exceeds a certain tolerance."),Object(o.b)("p",null,"For the bottom subregion, the pixels right outside the bottom boundary are (almost) all red (Texture), therefore this subregion is classified as Texture and filled with Texture elements."),Object(o.b)("p",null,"For the top subregion, the pixels outside the left, top, and right sides of the boundary are considered. All of those pixels are background (Blank), so this subregion is classified as Blank."),Object(o.b)("p",null,"After filling, the shape of the ellipse is completed, as follows:"),Object(o.b)(r.a,{src:"shape-sense/simple/ellipse_complete.png",alt:"Complete ellipse",mdxType:"Figure"}),Object(o.b)("p",null,"If we move the hole around, shape completion yields the following results:"),Object(o.b)(r.a,{src:"shape-sense/simple/ellipse_diff_holes.png",alt:"Complete ellipses with different holes",mdxType:"Figure"}),Object(o.b)("h2",{id:"complex-shape-completion"},"Complex Shape Completion"),Object(o.b)("p",null,"The process of shape completion shown above has been rather straightforward because there is a strong assumption - the hole cuts the shape at exactly 2 endpoints only. Consider the following case:"),Object(o.b)(r.a,{src:"shape-sense/complex/ellipse_hole_across.png",text:"At a glance, we can tell how the endpoints should be grouped - A with B, and C with D, but how can we model the problem to match the endpoints such that the result of color filling always makes sense?",alt:"Ellipse with a long hole cutting its boundary at 4 endpoints",mdxType:"Figure"}),Object(o.b)("h3",{id:"endpoint-matching"},"Endpoint Matching"),Object(o.b)("h4",{id:"failed-attempt-local-proximity"},"Failed attempt: Local Proximity"),Object(o.b)("p",null,"An intuitive approach might be by endpoint proximity in a greedy manner. If we simply connect each endpoint to its nearest neighbor, the correct matching is found for the above case. However, this approach ceases to work for the following case:"),Object(o.b)(r.a,{src:"shape-sense/complex/ellipse_local_proximity_counterexample.png",text:"The correct matching seems to be A with B and C with D, but the top two endpoints are the closest.",alt:"Tall hole over ellipse.",mdxType:"Figure"}),Object(o.b)("h4",{id:"avoiding-intersections"},"Avoiding Intersections"),Object(o.b)("p",null,"Problematic matchings are the ones that lead to intersecting curves. If intersection occurs, the resulting shape deforms and there may be subregions that are surrounded by others, leading to problems in color filling. Therefore, the key of endpoint matching lies in ",Object(o.b)("strong",{parentName:"p"},"avoiding intersections"),"."),Object(o.b)("p",null,"Before intrapolation, some intersecting curves can already be identified by looking at endpoint connections that intersect."),Object(o.b)("p",null,"Imagine we have 4 endpoints A, B, C, and D. If the line segment AB intersects with CD, then the curve intrapolated from A to B must intersect with that from C to D."),Object(o.b)(r.a,{src:"shape-sense/complex/line_intersect_implies_curve_intersect.png",alt:"Line intersection among endpoints implies intersection of intrapolated curves",mdxType:"Figure"}),Object(o.b)("p",null,"Therefore, the first step to avoiding intersecting curves is to filter out matchings that contain intersecting lines."),Object(o.b)("p",null,"This ",Object(o.b)("a",{href:"//prase.cz/kalva/putnam/psoln/psol794.html",parentName:"p"},"webpage")," shows that minimizing the total length of endpoint connections is equivalent to finding a matching with no intersecting connections. Hence the problem is reduced to a ",Object(o.b)("a",{href:"//core.ac.uk/download/pdf/82212931.pdf",parentName:"p"},"Euclidean Bipartite Matching Problem"),", i.e. optimizing the global weights over matchings. The ",Object(o.b)("a",{href:"//en.wikipedia.org/wiki/Hungarian_algorithm",parentName:"p"},"Hungarian algorithm")," is used to solve such a problem."),Object(o.b)("p",null,"The rest of the intersecting curves have to be caught and filtered out after intrapolation has taken place. Bézier curve intersection can be detected by a recursive method called ",Object(o.b)("a",{href:"//en.wikipedia.org/wiki/De_Casteljau%27s_algorithm",parentName:"p"},"De Casteljau's (Bézier Clipping) algorithm"),", which is implemented in ",Object(o.b)("a",{href:"//crates.io/crates/flo_curves",parentName:"p"},"flo_curves"),", the Bézier curve library we use."),Object(o.b)("h2",{id:"robustness"},"Robustness"),Object(o.b)("p",null,"Throughout the process of development, we encountered many edge cases where the pipeline would break down when faced with certain geometrical configurations. For example, an endpoint detected at the corner of the hole may or may not be useful, because it may be an edge entering the hole at a corner, or it may just be the hole touching an edge with its corner."),Object(o.b)("p",null,"As much as we hope to correctly handle every single situation (if it's possible in the first place), we figured, from an engineering perspective, that we want an effective way to secure maximum overall robustness with a reasonable amount of effort."),Object(o.b)("p",null,"From experimentation, we observed that most of the pain-inducing geometrical configurations were deformed once we move the hole by just 1 pixel. Therefore, we decided that once the pipeline breaks down, it should try to ",Object(o.b)("strong",{parentName:"p"},"recover by expanding the hole by 1 pixel in each direction"),". If it successfully produces something in one of these attempts, that result is used."),Object(o.b)("hr",null),Object(o.b)(r.a,{src:"shape-sense/animated_demo.gif",alt:"Animated Demo.",mdxType:"Figure"}),Object(o.b)("p",null,"As shown above, the performance of our implementation is stable for the most part. Occasionally, the pipeline (arguably) incorrectly handles the cases when tail tangents are (nearly) coincident to the hole boundaries."),Object(o.b)(r.a,{src:"shape-sense/incorrect.png",alt:"Arguably incorrect case.",mdxType:"Figure"}),Object(o.b)("h2",{id:"discussion"},"Discussion"),Object(o.b)("p",null,"The direct application of this algorithm is symbolic recognition, where a part of a symbol might be obscured artificially or accidentally."),Object(o.b)("p",null,"It can also be used in image repairing provided we are able to construct a high level shape structures of a natural photograph."),Object(o.b)("p",null,"As only the local information around the unknown region is used, the above shape reconstruction operation is entropy neutral, where no new information is introduced and no priori knowledge is assumed."),Object(o.b)("p",null,"This is a key factor, consider that if we have priori knowledge or simply are making wild guesses to what the original symbol might be, it completely changes the problem or actually defies the reason of shape completion."),Object(o.b)("p",null,"Under the symbolic recognition framework we propose (will be detailed in another article), recognition is a macroscopic statistical measurement that would greatly benefit from missing pieces filled in."))}void 0!==h&&h&&h===Object(h)&&Object.isExtensible(h)&&!h.hasOwnProperty("__filemeta")&&Object.defineProperty(h,"__filemeta",{configurable:!0,value:{name:"MDXContent",filename:"src/shapesense.mdx"}}),h.isMDXComponent=!0}}]);
//# sourceMappingURL=component---src-shapesense-mdx-a28963d66c7dc0995df0.js.map