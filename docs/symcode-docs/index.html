<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><style data-href="/styles.2543ff947a193d7f33b1.css">@import url(https://fonts.googleapis.com/css?family=Inconsolata&display=swap);@import url(https://fonts.googleapis.com/css?family=Source+Sans+Pro&display=swap);</style><meta name="generator" content="Gatsby 2.24.85"/><title data-rh="true">SymCode | Vision Cortex</title><meta data-rh="true" name="description" content="Semantic Computer Vision"/><meta data-rh="true" property="og:title" content="SymCode"/><meta data-rh="true" property="og:description" content="Semantic Computer Vision"/><meta data-rh="true" property="og:type" content="website"/><meta data-rh="true" name="twitter:card" content="summary"/><meta data-rh="true" name="twitter:title" content="SymCode"/><meta data-rh="true" name="twitter:description" content="Semantic Computer Vision"/><link as="script" rel="preload" href="/webpack-runtime-4ecf928c84a27444c6a9.js"/><link as="script" rel="preload" href="/styles-31f023f48facb69035d3.js"/><link as="script" rel="preload" href="/framework-bc0eb5446d96805b728a.js"/><link as="script" rel="preload" href="/app-22f19c56fe75b354f95d.js"/><link as="script" rel="preload" href="/798c9f31-55401554f16c5ec017b9.js"/><link as="script" rel="preload" href="/c8b6962d6148e584a9f22a767ed8f9cc94dfa8ff-cc82b785e04af3879186.js"/><link as="script" rel="preload" href="/component---src-symcode-mdx-ab53366765a4d3ee24ae.js"/><link as="fetch" rel="preload" href="/page-data/symcode-docs/page-data.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/sq/d/1635659820.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/app-data.json" crossorigin="anonymous"/></head><body><div id="___gatsby"><div style="outline:none" tabindex="-1" id="gatsby-focus-wrapper"><style data-emotion-css="1ouyflx">.css-1ouyflx{font-family:'Source Sans Pro',sans-serif;font-size:20px;font-weight:400;line-height:1.5;color:var(--theme-ui-colors-text,#2D3747);background-color:var(--theme-ui-colors-background,#FFFFFF);}</style><div class="css-1ouyflx"><style data-emotion-css="jrjj6h">.css-jrjj6h > div{-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;}</style><style data-emotion-css="1ubpee3">.css-1ubpee3{min-height:100vh;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}.css-1ubpee3 > div{-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;}</style><style data-emotion-css="hbri28">.css-hbri28{box-sizing:border-box;min-width:0;min-height:100vh;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}.css-hbri28 > div{-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;}</style><div data-testid="layout" class="css-hbri28"><style data-emotion-css="1xva7m0">body{margin:0;padding:0;}.icon-link{display:none;}.with-overlay{overflow:hidden;}</style><style data-emotion-css="zf0iqh">.css-zf0iqh{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;min-height:100vh;}</style><style data-emotion-css="1tjxv7i">.css-1tjxv7i{-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;min-height:100vh;}</style><style data-emotion-css="238csb">.css-238csb{box-sizing:border-box;min-width:0;-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;min-height:100vh;}</style><main class="css-238csb"><style data-emotion-css="18wmtq">.css-18wmtq{background-color:var(--theme-ui-colors-header-bg,#F5F6F7);position:relative;z-index:1;border-bottom:1px solid var(--theme-ui-colors-border,#CED4DE);}</style><div data-testid="header" class="css-18wmtq"><style data-emotion-css="zankq9">.css-zankq9{display:none;position:absolute;top:calc(100% + 15px);left:30px;}@media screen and (max-width:57.5em){.css-zankq9{display:block;}}</style><style data-emotion-css="1s0wdqz">.css-1s0wdqz{box-sizing:border-box;min-width:0;display:none;position:absolute;top:calc(100% + 15px);left:30px;}@media screen and (max-width:57.5em){.css-1s0wdqz{display:block;}}</style><div class="css-1s0wdqz"><style data-emotion-css="4019lz">.css-4019lz{padding:0;outline:none;background:transparent;border:none;color:var(--theme-ui-colors-header-text,#2D3747);opacity:0.5;cursor:pointer;}.css-4019lz:hover{cursor:pointer;}</style><button class="css-4019lz"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line></svg></button></div><style data-emotion-css="z6jak6">.css-z6jak6{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;padding-left:32px;padding-right:32px;position:relative;height:80px;}</style><div class="css-z6jak6"><style data-emotion-css="xenp3v">.css-xenp3v{-webkit-letter-spacing:-0.02em;-moz-letter-spacing:-0.02em;-ms-letter-spacing:-0.02em;letter-spacing:-0.02em;font-weight:600;font-size:24px;}</style><style data-emotion-css="1abzlu">.css-1abzlu{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-letter-spacing:-0.02em;-moz-letter-spacing:-0.02em;-ms-letter-spacing:-0.02em;letter-spacing:-0.02em;font-weight:600;font-size:24px;}</style><style data-emotion-css="ug0363">.css-ug0363{box-sizing:border-box;min-width:0;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-letter-spacing:-0.02em;-moz-letter-spacing:-0.02em;-ms-letter-spacing:-0.02em;letter-spacing:-0.02em;font-weight:600;font-size:24px;}</style><div data-testid="logo" class="css-ug0363"><style data-emotion-css="gyijir">.css-gyijir{font-weight:600;color:var(--theme-ui-colors-header-text,#2D3747);-webkit-text-decoration:none;text-decoration:none;}.css-gyijir:hover{color:var(--theme-ui-colors-primary,#0B5FFF);}</style><a style="height:48px" class="css-gyijir" href="/"><img style="height:100%" src="/public/visioncortex-logo.svg"/></a></div><style data-emotion-css="k008qs">.css-k008qs{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}</style><style data-emotion-css="80zs6q">.css-80zs6q{box-sizing:border-box;min-width:0;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}</style><div class="css-80zs6q"><style data-emotion-css="12z0wuy">.css-12z0wuy{margin-right:8px;}</style><style data-emotion-css="q6cf68">.css-q6cf68{box-sizing:border-box;min-width:0;margin-right:8px;}</style><div class="css-q6cf68"><style data-emotion-css="1is33jg">.css-1is33jg{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;outline:none;padding:12px;border:none;border-radius:9999px;background-color:var(--theme-ui-colors-header-button-bg,#0B5FFF);color:var(--theme-ui-colors-header-button-color,#FFFFFF);font-size:12px;font-weight:600;cursor:pointer;}</style><a href="https://github.com/visioncortex" target="_blank" rel="noopener noreferrer" class="css-1is33jg"><svg xmlns="http://www.w3.org/2000/svg" width="15" height="15" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path></svg></a></div><button aria-label="Switch to light mode" class="css-1is33jg"><svg xmlns="http://www.w3.org/2000/svg" width="15" height="15" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"></circle><line x1="12" y1="1" x2="12" y2="3"></line><line x1="12" y1="21" x2="12" y2="23"></line><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line><line x1="1" y1="12" x2="3" y2="12"></line><line x1="21" y1="12" x2="23" y2="12"></line><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line></svg></button></div></div></div><style data-emotion-css="1nfi0ai">.css-1nfi0ai{padding-top:0;padding-bottom:0;-webkit-flex:1;-ms-flex:1;flex:1;display:grid;grid-template-columns:250px minmax(0,1fr);min-height:100vh;}@media screen and (max-width:57.5em){.css-1nfi0ai{display:block;}}</style><div class="css-1nfi0ai"><style data-emotion-css="1tn7q1x">.css-1tn7q1x{z-index:999;position:fixed;top:81px;right:0;bottom:0;left:0;background:rgba(0,0,0,0.6);-webkit-transition:all .2s ease-out;transition:all .2s ease-out;visibility:hidden;opacity:0;}</style><style data-emotion-css="h4snl3">.css-h4snl3{box-sizing:border-box;min-width:0;z-index:999;position:fixed;top:81px;right:0;bottom:0;left:0;background:rgba(0,0,0,0.6);-webkit-transition:all .2s ease-out;transition:all .2s ease-out;visibility:hidden;opacity:0;}</style><div class="css-h4snl3"></div><style data-emotion-css="1ethd5x">.css-1ethd5x{padding-top:32px;padding-bottom:32px;padding-left:32px;padding-right:32px;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;position:-webkit-sticky;position:sticky;top:0;z-index:1;min-width:0;max-height:100vh;border-right:1px solid var(--theme-ui-colors-border,#CED4DE);overflow:auto;-webkit-overflow-scrolling:touch;background-color:var(--theme-ui-colors-sidebar-bg,#FFFFFF);}@media screen and (max-width:57.5em){.css-1ethd5x{z-index:9999;display:block;position:fixed;top:81px;left:0;bottom:0;width:256px;padding-left:32px;padding-right:32px;background-color:var(--theme-ui-colors-background,#FFFFFF);-webkit-transition:-webkit-transform .2s ease-out;-webkit-transition:transform .2s ease-out;transition:transform .2s ease-out;-webkit-transform:translateX(-100%);-ms-transform:translateX(-100%);transform:translateX(-100%);}}</style><style data-emotion-css="1li9yso">.css-1li9yso{box-sizing:border-box;min-width:0;padding-top:32px;padding-bottom:32px;padding-left:32px;padding-right:32px;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;position:-webkit-sticky;position:sticky;top:0;z-index:1;min-width:0;max-height:100vh;border-right:1px solid var(--theme-ui-colors-border,#CED4DE);overflow:auto;-webkit-overflow-scrolling:touch;background-color:var(--theme-ui-colors-sidebar-bg,#FFFFFF);}@media screen and (max-width:57.5em){.css-1li9yso{z-index:9999;display:block;position:fixed;top:81px;left:0;bottom:0;width:256px;padding-left:32px;padding-right:32px;background-color:var(--theme-ui-colors-background,#FFFFFF);-webkit-transition:-webkit-transform .2s ease-out;-webkit-transition:transform .2s ease-out;transition:transform .2s ease-out;-webkit-transform:translateX(-100%);-ms-transform:translateX(-100%);transform:translateX(-100%);}}</style><div data-testid="sidebar" class="css-1li9yso"><style data-emotion-css="lcm9hh">.css-lcm9hh{margin-bottom:16px;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}</style><div data-testid="nav-search" class="css-lcm9hh"><style data-emotion-css="1mo6uhh">.css-1mo6uhh{color:var(--theme-ui-colors-border,#CED4DE);margin-right:8px;}</style><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="css-1mo6uhh"><circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line></svg><style data-emotion-css="1bbueiu">.css-1bbueiu{outline:none;background:none;border:none;color:var(--theme-ui-colors-text,#2D3747);font-size:14px;}</style><input placeholder="Type to search..." value="" class="css-1bbueiu"/></div><style data-emotion-css="1rqvyud">.css-1rqvyud{margin-top:8px;margin-bottom:8px;display:block;color:var(--theme-ui-colors-sidebar-navGroup,#2D3747);-webkit-text-decoration:none;text-decoration:none;font-size:16px;}.css-1rqvyud.active{color:var(--theme-ui-colors-sidebar-navLinkActive,#0B5FFF);}</style><a class="css-1rqvyud" href="/">Vision Cortex</a><a aria-current="page" class="css-1rqvyud active" href="/symcode-docs">SymCode</a><style data-emotion-css="1ooej63">.css-1ooej63{margin-top:8px;margin-bottom:8px;display:block;color:var(--theme-ui-colors-sidebar-tocLink,#67788a);-webkit-text-decoration:none;text-decoration:none;font-size:14px;margin-left:16px;position:relative;}.css-1ooej63.active{color:var(--theme-ui-colors-sidebar-tocLinkActive,#1D2330);}.css-1ooej63.active::before{content:"";position:absolute;display:block;top:2px;left:-8px;height:1rem;background-color:var(--theme-ui-colors-primary,#0B5FFF);-webkit-transition:width 200ms ease 0s;transition:width 200ms ease 0s;width:2px;border-radius:1px;}</style><a class=" css-1ooej63" href="/symcode-docs#forewords">Forewords</a><a class=" css-1ooej63" href="/symcode-docs#background">Background</a><a class=" css-1ooej63" href="/symcode-docs#goals-and-constraints">Goals and Constraints</a><a class=" css-1ooej63" href="/symcode-docs#design-of-symbols">Design of symbols</a><a class=" css-1ooej63" href="/symcode-docs#trace-of-shapes">Trace of shapes</a><a class=" css-1ooej63" href="/symcode-docs#trace-of-symcode">Trace of SymCode</a><a class=" css-1ooej63" href="/symcode-docs#image-processing-pipeline">Image Processing Pipeline</a><a class=" css-1ooej63" href="/symcode-docs#conclusion">Conclusion</a><a class=" css-1ooej63" href="/symcode-docs#about-vision-cortex">About Vision Cortex</a><a class="css-1rqvyud" href="/impression-docs">Impression</a><a class="css-1rqvyud" href="/vtracer-docs">VTracer</a></div><script async="" type="text/javascript">
      (function(c,l,a,r,i,t,y){
          c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
          t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
          y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
      })(window, document, "clarity", "script", "403biw7tra");
    </script><style data-emotion-css="1w3d2mg">.css-1w3d2mg{background-color:var(--theme-ui-colors-background,#FFFFFF);position:relative;max-width:1280px;padding-top:48px;padding-bottom:48px;padding-left:32px;padding-right:32px;padding:32px;}@media screen and (max-width:57.5em){.css-1w3d2mg{padding-top:48px;padding-bottom:32px;padding-left:32px;padding-right:32px;}}</style><style data-emotion-css="kjtkh5">.css-kjtkh5{width:100%;min-width:0;max-width:1280px;margin-left:auto;margin-right:auto;padding:32px;background-color:var(--theme-ui-colors-background,#FFFFFF);position:relative;max-width:1280px;padding-top:48px;padding-bottom:48px;padding-left:32px;padding-right:32px;padding:32px;}@media screen and (max-width:57.5em){.css-kjtkh5{padding-top:48px;padding-bottom:32px;padding-left:32px;padding-right:32px;}}</style><style data-emotion-css="1307vk3">.css-1307vk3{box-sizing:border-box;min-width:0;width:100%;min-width:0;max-width:1280px;margin-left:auto;margin-right:auto;padding:32px;background-color:var(--theme-ui-colors-background,#FFFFFF);position:relative;max-width:1280px;padding-top:48px;padding-bottom:48px;padding-left:32px;padding-right:32px;padding:32px;}@media screen and (max-width:57.5em){.css-1307vk3{padding-top:48px;padding-bottom:32px;padding-left:32px;padding-right:32px;}}</style><div data-testid="main-container" class="css-1307vk3"><style data-emotion-css="1vci3bl">.css-1vci3bl{padding:0;margin:0;margin-bottom:16px;font-size:48px;font-family:'Source Sans Pro',sans-serif;line-height:1.125;font-weight:700;}</style><h1 id="symcode-the-symbolic-barcode-for-humans-and-machines" class="css-1vci3bl">SymCode: The Symbolic Barcode for Humans and Machines</h1><style data-emotion-css="1ftn47p">.css-1ftn47p{padding:0;margin:0;margin-bottom:16px;}</style><p class="css-1ftn47p">Authors: <style data-emotion-css="1iv9jyz">.css-1iv9jyz{color:var(--theme-ui-colors-primary,#0B5FFF);-webkit-text-decoration:none;text-decoration:none;}.css-1iv9jyz:hover{color:secondary;-webkit-text-decoration:underline;text-decoration:underline;}</style><a href="//github.com/tyt2y3" class="css-1iv9jyz">Chris Tsang</a> and <a href="//github.com/shpun817" class="css-1iv9jyz">Sanford Pun</a> | Published: 2021-04-03</p><style data-emotion-css="2abk98">.css-2abk98{padding:0;margin:0;margin-bottom:16px;border:0;border-bottom:1px solid var(--theme-ui-colors-border,#CED4DE);margin-top:-1px;}</style><hr class="css-2abk98"/><p class="css-1ftn47p">This is our story of the design and implementation of a symbolic barcode system.</p><p class="css-1ftn47p">[demo video]</p><h2 id="forewords"><style data-emotion-css="1r0pe6c">.css-1r0pe6c{color:inherit;-webkit-text-decoration:none;text-decoration:none;}.css-1r0pe6c:hover{-webkit-text-decoration:underline;text-decoration:underline;}</style><a href="#forewords" class="css-1r0pe6c">Forewords</a></h2><p class="css-1ftn47p">If you are lucky enough to live in a place where an Amazon Go store is nearby, you definitely should visit it. It is packed full of esoteric technology that enthusiast like us get super intrigued. One item that caught our eyes was the labels on the salad and sandwiches in the ready-made food section.</p><div><img alt="Photo within an Amazon Go store" style="display:block;margin-left:auto;margin-right:auto;max-width:100%" src="/public/symcode/Amazon Go Seattle - crop.jpg"/><h4 style="text-align:center">Photo within an Amazon Go store</h4></div><style data-emotion-css="16r6o5s">.css-16r6o5s{padding:0;margin:0;margin-bottom:32px;margin-left:0;margin-right:0;margin-top:32px;padding-top:16px;padding-bottom:16px;padding-left:32px;padding-right:32px;background-color:var(--theme-ui-colors-blockquote-bg,#F5F6F7);border-left:5px solid var(--theme-ui-colors-blockquote-border,#CED4DE);color:var(--theme-ui-colors-blockquote-color,#67788a);font-style:italic;}.css-16r6o5s > p{margin:0;}</style><blockquote class="css-16r6o5s"><p class="css-1ftn47p">Photo by Sikander Iqbal via <a href="https://commons.wikimedia.org/wiki/File:Amazon_Go_-_Seattle_(20180804111213).jpg" class="css-1iv9jyz">Wikimedia Commons</a></p></blockquote><p class="css-1ftn47p">There printed a matrix of cute little circles and squares! It must be a barcode of some sort. From our observation, there are always three diamonds on each label, which can be placed at anywhere on the 6x4 matrix. The circles are the bits of the barcode, so we can assume that the barcode can encode 24 bit raw data.</p><p class="css-1ftn47p">Our attempt to decipher the &#x27;<a href="/reversi-docs" class="css-1iv9jyz">Amazon Reversi Code</a>&#x27; was futile, but this is the start of the story.</p><h2 id="background"><a href="#background" class="css-1r0pe6c">Background</a></h2><p class="css-1ftn47p">A bit of context for the unfamiliar reader, the name Barcode is referring to the labels we still find in virtually every packaged products today. Barcode encode data by varying the widths and spacings of the vertical bars, which are to be scanned by a laser beam crossing horizontally. With the advent of image sensors, 2D barcodes were developed, where QR code and Aztec Code are some of the most well-known.</p><p class="css-1ftn47p">In general, 2D barcode scanner works as follows:</p><style data-emotion-css="cvh4i0">.css-cvh4i0{padding:0;margin:0;margin-bottom:16px;list-style-position:outside;list-style-image:none;margin-left:16px;}</style><ol class="css-cvh4i0"><style data-emotion-css="q43a5f">.css-q43a5f{margin-bottom:4px;padding-left:0;}.css-q43a5f ol{margin-top:8px;margin-bottom:8px;margin-left:16px;}.css-q43a5f ul{margin-top:8px;margin-bottom:8px;margin-left:16px;}.css-q43a5f p{margin-bottom:8px;}</style><li class="css-q43a5f"><p class="css-1ftn47p">Locate the finders. These finders act as a trigger to tell the scanner that &#x27;here is a barcode!&#x27;. The finders have to be easily detectable yet not interfering with the data modules.</p></li><li class="css-q43a5f"><p class="css-1ftn47p">Attempt to scan and read metadata surrounding the finder candidates. The metadata usually includes a format code and timing patterns.</p></li><li class="css-q43a5f"><p class="css-1ftn47p">If the previous step succeeds, the scanner would sample the entire barcode to construct a raw bit string. A checksum operation is done to detect errors.</p></li><li class="css-q43a5f"><p class="css-1ftn47p">If the previous step succeeds, the payload is extract from the raw bits, which usually involves some bit masking and shuffling.</p></li></ol><p class="css-1ftn47p">This framework has aged well and they are quite robust and low-cost to implement in embedded systems. However, they are meant to be read by machines and not by our naked eyes. They are not designed for aesthetics and are impossible for humans to comprehend.</p><h2 id="goals-and-constraints"><a href="#goals-and-constraints" class="css-1r0pe6c">Goals and Constraints</a></h2><p class="css-1ftn47p">Our goal is to design a barcode system that are both human-readable and machine-readable. We now turn our attention to human readability by studying human languages.</p><p class="css-1ftn47p">Machines run on bits, so we can say the alphabet consists of 0 and 1. In human languages, we have a larger set of alphabets. In English, we have 26 distinct lowercase letters. In Korean, characters are constructed by composing 2 to 6 elements from a set of 40 distinct Jamo.</p><p class="css-1ftn47p">There is a direct tradeoff between information density and visual ambiguity. If the symbol set is too large, humans would have difficulty in remembering all of them. In addition, there may be some visually similar symbols that are hard to disambiguate. If the symbol set is too small, the same message has to be encoded with more symbols, which again, humans often have a hard time in processing long strings.</p><p class="css-1ftn47p">We determined that a symbol set in the range of 16 to 64 symbols is a good balance.</p><h2 id="design-of-symbols"><a href="#design-of-symbols" class="css-1r0pe6c">Design of symbols</a></h2><p class="css-1ftn47p">What makes good symbols?</p><ol class="css-cvh4i0"><li class="css-q43a5f"><p class="css-1ftn47p">Prominence
First, the symbols have to stand out from the natural world, to manifest that they are created deliberately to convey a message but not a result of some natural phenomenon.</p></li><li class="css-q43a5f"><p class="css-1ftn47p">Repeatable
Symbols are constructed with specific tools and processes that can be taught to other people. The meaning of a symbol should remain the same when reproduced, in which variation is tolerated.</p></li><li class="css-q43a5f"><p class="css-1ftn47p">Distinctive
Symbols within a set should not be similar with each other and have distinctive features allowing the reader to resolve ambiguity between symbols.</p></li><li class="css-q43a5f"><p class="css-1ftn47p">Aesthetics
Finally, good symbols should observe the aesthetics rules of the human eye, including being anti-symmetric, rotational symmetric, balanced and consistent. As a pointer, the <a href="https://en.wikipedia.org/wiki/Gestalt_psychology" class="css-1iv9jyz">Gestalt Principles</a> are fantastic rules of thumb.</p></li></ol><p class="css-1ftn47p">With the above rules in mind, we designed a minimalistic symbol set. Each symbol is composed of multiple triangles, the basic geometric primitive. Each symbol is symmetric or anti-symmetric in overall, but exhibits asymmetry internally. They are like Tangram, in which a human child can easily reproduce the symbols by assembly some triangular pieces together.</p><p class="css-1ftn47p">The next section would quantitatively analyze and justify this design methodology.</p><h2 id="trace-of-shapes"><a href="#trace-of-shapes" class="css-1r0pe6c">Trace of shapes</a></h2><p class="css-1ftn47p">The naive way to match a shape against a symbol set is to perform a linear search, XOR it with every symbol and then chooses the one with the lowest delta. It works in principle, but is inefficient. Ideally, an algorithm can condense a complex shape into a feature vector, which we can lookup in the feature space of the symbol set for the nearest neighbour and arrive to a match.</p><p class="css-1ftn47p">Instead of using an array of real numbers, we devised that an array of bits are sufficient to capture the essence of symbols, and from now on we refer this bit string as &#x27;trace&#x27;.</p><h3 id="the-english-alphabet"><a href="#the-english-alphabet" class="css-1r0pe6c">The English alphabet</a></h3><p class="css-1ftn47p">Now, let us take a closer look at the lowercase English alphabet set to illustrate this idea.</p><div><img alt="English alphabets" style="display:block;margin-left:auto;margin-right:auto;height:200px;max-width:100%" src="/public/symcode/english alphabet.svg"/><h4 style="text-align:center">English alphabets</h4></div><p class="css-1ftn47p">First off, we can classify the 26 alphabets as either tall or short, giving:</p><div><style data-emotion-css="1h0sj8d">.css-1h0sj8d{padding:16px;margin:0;margin-bottom:32px;font-size:85%;margin-top:32px;text-align:left;font-family:Inconsolata;border-radius:4px;}.css-1h0sj8d dark{[object Object];}.css-1h0sj8d light{[object Object];}</style><pre class=" prism-code language-text css-1h0sj8d" style="font-family:Inconsolata;color:#393A34;background-color:#f6f8fa;overflow-x:auto" data-testid="code"><div class="token-line" style="font-family:Inconsolata;color:#393A34"><style data-emotion-css="1baulvz">.css-1baulvz{display:inline-block;}</style><span class="token plain css-1baulvz">Tall: b d f g h j k l p q t y</span></div><div class="token-line" style="font-family:Inconsolata;color:#393A34"><span class="token plain css-1baulvz">Short: a c e i m n o r s u v w x z</span></div></pre></div><p class="css-1ftn47p">Next, we can divide the letter into two halfs horizontally and compare their weights:</p><div><pre class=" prism-code language-text css-1h0sj8d" style="font-family:Inconsolata;color:#393A34;background-color:#f6f8fa;overflow-x:auto" data-testid="code"><div class="token-line" style="font-family:Inconsolata;color:#393A34"><span class="token plain css-1baulvz">Left &gt; right: b c f h k p r t y</span></div><div class="token-line" style="font-family:Inconsolata;color:#393A34"><span class="token plain css-1baulvz">Left &lt; right: a d g q</span></div><div class="token-line" style="font-family:Inconsolata;color:#393A34"><span class="token plain css-1baulvz">Left ~ right: e i j l m n o s u v w x z</span></div></pre></div><p class="css-1ftn47p">Then, we can divide the letter into two halfs vertically and compare their weights:</p><div><pre class=" prism-code language-text css-1h0sj8d" style="font-family:Inconsolata;color:#393A34;background-color:#f6f8fa;overflow-x:auto" data-testid="code"><div class="token-line" style="font-family:Inconsolata;color:#393A34"><span class="token plain css-1baulvz">Up &gt; down: f m n p q r y</span></div><div class="token-line" style="font-family:Inconsolata;color:#393A34"><span class="token plain css-1baulvz">Up &lt; down: b d h k u</span></div><div class="token-line" style="font-family:Inconsolata;color:#393A34"><span class="token plain css-1baulvz">Up ~ down: a c e g i j l o s t v w x z</span></div></pre></div><p class="css-1ftn47p">At this point, we had the following:</p><div><pre class=" prism-code language-text css-1h0sj8d" style="font-family:Inconsolata;color:#393A34;background-color:#f6f8fa;overflow-x:auto" data-testid="code"><div class="token-line" style="font-family:Inconsolata;color:#393A34"><span class="token plain css-1baulvz">a: SR=</span></div><div class="token-line" style="font-family:Inconsolata;color:#393A34"><span class="token plain css-1baulvz">b: TLD</span></div><div class="token-line" style="font-family:Inconsolata;color:#393A34"><span class="token plain css-1baulvz">c: SL=</span></div><div class="token-line" style="font-family:Inconsolata;color:#393A34"><span class="token plain css-1baulvz">d: TRD</span></div><div class="token-line" style="font-family:Inconsolata;color:#393A34"><span class="token plain css-1baulvz">e: S==</span></div><div class="token-line" style="font-family:Inconsolata;color:#393A34"><span class="token plain css-1baulvz">f: TLU</span></div><div class="token-line" style="font-family:Inconsolata;color:#393A34"><span class="token plain css-1baulvz">g: TR=</span></div><div class="token-line" style="font-family:Inconsolata;color:#393A34"><span class="token plain css-1baulvz">h: TLD</span></div><div class="token-line" style="font-family:Inconsolata;color:#393A34"><span class="token plain css-1baulvz">i: S==</span></div><div class="token-line" style="font-family:Inconsolata;color:#393A34"><span class="token plain css-1baulvz">j: T==</span></div><div class="token-line" style="font-family:Inconsolata;color:#393A34"><span class="token plain css-1baulvz">k: TLD</span></div><div class="token-line" style="font-family:Inconsolata;color:#393A34"><span class="token plain css-1baulvz">l: T==</span></div><div class="token-line" style="font-family:Inconsolata;color:#393A34"><span class="token plain css-1baulvz">m: S=U</span></div><div class="token-line" style="font-family:Inconsolata;color:#393A34"><span class="token plain css-1baulvz">n: S=U</span></div><div class="token-line" style="font-family:Inconsolata;color:#393A34"><span class="token plain css-1baulvz">o: S==</span></div><div class="token-line" style="font-family:Inconsolata;color:#393A34"><span class="token plain css-1baulvz">p: TLU</span></div><div class="token-line" style="font-family:Inconsolata;color:#393A34"><span class="token plain css-1baulvz">q: TRU</span></div><div class="token-line" style="font-family:Inconsolata;color:#393A34"><span class="token plain css-1baulvz">r: SLU</span></div><div class="token-line" style="font-family:Inconsolata;color:#393A34"><span class="token plain css-1baulvz">s: S==</span></div><div class="token-line" style="font-family:Inconsolata;color:#393A34"><span class="token plain css-1baulvz">t: TLD</span></div><div class="token-line" style="font-family:Inconsolata;color:#393A34"><span class="token plain css-1baulvz">u: S=D</span></div><div class="token-line" style="font-family:Inconsolata;color:#393A34"><span class="token plain css-1baulvz">v: S==</span></div><div class="token-line" style="font-family:Inconsolata;color:#393A34"><span class="token plain css-1baulvz">w: S==</span></div><div class="token-line" style="font-family:Inconsolata;color:#393A34"><span class="token plain css-1baulvz">x: S==</span></div><div class="token-line" style="font-family:Inconsolata;color:#393A34"><span class="token plain css-1baulvz">y: TLU</span></div><div class="token-line" style="font-family:Inconsolata;color:#393A34"><span class="token plain css-1baulvz">z: S==</span></div></pre></div><p class="css-1ftn47p">Group by trace:</p><div><pre class=" prism-code language-text css-1h0sj8d" style="font-family:Inconsolata;color:#393A34;background-color:#f6f8fa;overflow-x:auto" data-testid="code"><div class="token-line" style="font-family:Inconsolata;color:#393A34"><span class="token plain css-1baulvz">SR=: a</span></div><div class="token-line" style="font-family:Inconsolata;color:#393A34"><span class="token plain css-1baulvz">TLD: b h k</span></div><div class="token-line" style="font-family:Inconsolata;color:#393A34"><span class="token plain css-1baulvz">SL=: c</span></div><div class="token-line" style="font-family:Inconsolata;color:#393A34"><span class="token plain css-1baulvz">TRD: d</span></div><div class="token-line" style="font-family:Inconsolata;color:#393A34"><span class="token plain css-1baulvz">S==: e i o s v w x z</span></div><div class="token-line" style="font-family:Inconsolata;color:#393A34"><span class="token plain css-1baulvz">TL=: t</span></div><div class="token-line" style="font-family:Inconsolata;color:#393A34"><span class="token plain css-1baulvz">TR=: g</span></div><div class="token-line" style="font-family:Inconsolata;color:#393A34"><span class="token plain css-1baulvz">T==: j l </span></div><div class="token-line" style="font-family:Inconsolata;color:#393A34"><span class="token plain css-1baulvz">S=U: m n</span></div><div class="token-line" style="font-family:Inconsolata;color:#393A34"><span class="token plain css-1baulvz">TLU: f p y</span></div><div class="token-line" style="font-family:Inconsolata;color:#393A34"><span class="token plain css-1baulvz">TRU: q</span></div><div class="token-line" style="font-family:Inconsolata;color:#393A34"><span class="token plain css-1baulvz">SLU: r</span></div><div class="token-line" style="font-family:Inconsolata;color:#393A34"><span class="token plain css-1baulvz">S=D: u</span></div></pre></div><p class="css-1ftn47p">Which is a surprisingly good classifier using only three comparisons. We can do more trinary comparisons on smaller partitions to further differentiate the collisions, but our investigation on English alphabets ends here for the scope of this article.</p><h3 id="symcode"><a href="#symcode" class="css-1r0pe6c">SymCode</a></h3><p class="css-1ftn47p">Our trace for SymCode symbols follows a similar scheme. We defined the symbol traces using only three comparisons (shape/weight analyses), namely vertical, horizontal, and diagonal comparisons.</p><p class="css-1ftn47p">If the &quot;number of dots&quot; in each of the four quadrants of a symbol (in order of top-left, top-right, bottom-left, bottom-right) are denoted by non-negative quantities a,b,c,d respectively, the three comparisons are defined as follows:</p><div><img alt="Grid quadrants" style="display:block;margin-left:auto;margin-right:auto;height:200px;max-width:100%" src="/public/symcode/grid abcd.svg"/><h4 style="text-align:center">Grid quadrants</h4></div><ul class="css-cvh4i0"><li class="css-q43a5f">Vertical comparison = (a+b) vs (c+d)</li><li class="css-q43a5f">Horizontal comparison = (a+c) vs (b+d)</li><li class="css-q43a5f">Diagonal comparison = (a+d) vs (b+c)</li></ul><p class="css-1ftn47p">Below are two examples:</p><div><img alt="LongRR symbol image" style="display:block;margin-left:auto;margin-right:auto;max-width:100%" src="/public/symcode/LongRR.png"/><h4 style="text-align:center">LongRR symbol image</h4></div><ul class="css-cvh4i0"><li class="css-q43a5f">Vertical comparison = Top ~ Bottom</li><li class="css-q43a5f">Horizontal comparison = Left &gt; Right</li><li class="css-q43a5f">Diagonal comparison = Backslash ~ Slash</li></ul><div><img alt="SmallDoubleLR symbol image" style="display:block;margin-left:auto;margin-right:auto;max-width:100%" src="/public/symcode/SmallDoubleLR.png"/><h4 style="text-align:center">SmallDoubleLR symbol image</h4></div><ul class="css-cvh4i0"><li class="css-q43a5f">Vertical comparison = Top ~ Bottom</li><li class="css-q43a5f">Horizontal comparison = Left ~ Right</li><li class="css-q43a5f">Diagonal comparison = Backslash &gt; Slash</li></ul><p class="css-1ftn47p">Each comparison has <style data-emotion-css="1vg6q84">.css-1vg6q84{font-weight:700;}</style><strong class="css-1vg6q84">3 possible outcomes (<!-- -->&lt;<!-- -->, <!-- -->&gt;<!-- -->, ~)</strong>. For simplicity, we assign <strong class="css-1vg6q84">2 bits</strong> to encode each comparison. Therefore, this naive implementation uses <strong class="css-1vg6q84">3 * 2 = 6 bits</strong> to store each trace.</p><p class="css-1ftn47p">The above worked well enough for sets of 16 symbols, but it was found inadequate for 32 symbols. Acute32 requires more comparisons for traces.</p><h2 id="trace-of-symcode"><a href="#trace-of-symcode" class="css-1r0pe6c">Trace of SymCode</a></h2><p class="css-1ftn47p">The following figure is Acute32&#x27;s alphabet set.</p><div><img alt="Acute32 alphabet set" style="display:block;margin-left:auto;margin-right:auto;width:480px;max-width:100%" src="/public/symcode/alphabet2.png"/><h4 style="text-align:center">Acute32 alphabet set</h4></div><p class="css-1ftn47p">Apart from the three basic comparisons explained in the previous section (<em class="css-0">V,H,D</em>), we also compare every pair of the four quadrants (each quadrant is compared to every other quadrant exactly once), requiring <strong class="css-1vg6q84">an extra of <em class="css-0">4 choose 2</em> = 6 comparisons</strong> (<em class="css-0">ab, cd, ac</em>, ...). The last comparison <em class="css-0">efgh</em> is explained in the details below.</p><div><img alt="Acute32 trace counts" style="display:block;margin-left:auto;margin-right:auto;width:600px;max-width:100%" src="/public/symcode/trace_counts_balanced.png"/><h4 style="text-align:center">Acute32 trace counts</h4></div><details><h3 id="side-note-efgh"><a href="#side-note-efgh" class="css-1r0pe6c">Side note: <style data-emotion-css="ueqitl">.css-ueqitl{font-family:Inconsolata;}</style><code class="css-ueqitl">efgh</code></a></h3><p class="css-1ftn47p">It is important to note that not any arbitrary extra comparisons are effective. The rule of thumb is each extra comparison should introduce new information than the existing ones, making them <strong class="css-1vg6q84">(at least partially) independent</strong> of each other. In general, comparisons that use <strong class="css-1vg6q84">different numbers of blocks</strong> should be independent. For example, in the previous section all comparisons used 2 blocks vs 2 blocks, so the extra ones in this section, which use 1 block vs 1 block, are all (partially) independent of the previous ones. This is because as more blocks are being considered at once, the scope of analysis becomes irreversibly broader - just like how you cannot retrieve neither <em class="css-0">x</em> nor <em class="css-0">y</em> from the sum <em class="css-0">x+y</em>.</p><p class="css-1ftn47p">Adding the extra ones results in a total of 3 + 6 = 9 comparisons. Using 2 bits to encode each, we are using 9 * 2 = <strong class="css-1vg6q84">18 bits</strong> to store each trace in Acute32.</p><p class="css-1ftn47p">Denote a comparison operation by &quot;U vs V&quot;. The vertical, horizontal, and diagonal comparisons become &quot;Top vs Bottom&quot;, &quot;Left vs Right&quot;, and &quot;Backslash vs Slash&quot; respectively. The rest of the comparisons become &quot;a vs b&quot;, &quot;c vs d&quot;, and so on. We set the bits as follows:</p><h3 id="for-each-comparison-u-vs-v"><a href="#for-each-comparison-u-vs-v" class="css-1r0pe6c">For each comparison U vs V</a></h3><ul class="css-cvh4i0"><li class="css-q43a5f">11 means &quot;U <!-- -->~<!-- --> V&quot;</li><li class="css-q43a5f">10 means &quot;U <!-- -->&gt;<!-- --> V&quot;</li><li class="css-q43a5f">01 means &quot;U <!-- -->&lt;<!-- --> V&quot;</li><li class="css-q43a5f">00 is invalid</li></ul><p class="css-1ftn47p">The trace of all 1&#x27;s, which happens when all four quadrants of the symbol share (approximately) the same number of dots, is shared by about one-third of the entire Acute32. This makes approximately one-third of the searches scan through 12 symbol images, which is 4 times that of most of the rest, which only scan through 3 symbol images.</p><p class="css-1ftn47p">Our solution here is one more comparison.</p><div><img alt="efgh (top/bottom/left/right) grid" style="display:block;margin-left:auto;margin-right:auto;max-width:100%" src="/public/symcode/efgh_grid.png"/><h4 style="text-align:center">efgh (top/bottom/left/right) grid</h4></div><p class="css-1ftn47p">We further partition the grid of each symbol image so that there are 4x4 = 16 small blocks, and denote the top/bottom/left/right blocks along the edge by <em class="css-0">e,f,g,h</em> respectively, as illustrated in the figure above. Next, we define an &quot;<em class="css-0">ef/gh</em> comparison&quot; which compares <em class="css-0">e+f</em> to <em class="css-0">g+h</em>.</p><p class="css-1ftn47p">Now we have a more balanced distribution.</p></details><h3 id="advantages-of-traces"><a href="#advantages-of-traces" class="css-1r0pe6c">Advantages of traces</a></h3><p class="css-1ftn47p">Traces enhance robustness against noisy inputs. The trace partitions the symbol set into smaller, mutually-exclusive subsets. As searching through traces is much more efficient than comparing with each symbol individually, traces also help with performance.</p><h2 id="image-processing-pipeline"><a href="#image-processing-pipeline" class="css-1r0pe6c">Image Processing Pipeline</a></h2><p class="css-1ftn47p">The processing pipeline of SymCode consists of 4 stages: <code class="css-ueqitl">finder</code>, <code class="css-ueqitl">fitter</code>, <code class="css-ueqitl">recognizer</code>, <code class="css-ueqitl">decoder</code>.</p><p class="css-1ftn47p">Each stage below begins with a more general description of the processing stage (general across any SymCode), followed by explanation of the implementation of Acute32.</p><h3 id="stage-1-locate-finder-candidates"><a href="#stage-1-locate-finder-candidates" class="css-1r0pe6c">Stage 1: Locate Finder Candidates</a></h3><p class="css-1ftn47p">We first binarize the input color image using an adaptive thresholding strategy, shapes are then extracted from a binary image by clustering.</p><p class="css-1ftn47p">The goal of this stage is to find the positions of all finder candidates in the frame.</p><p class="css-1ftn47p">A minimum of 4 feature points is needed because at least <strong class="css-1vg6q84">4 point correspondences</strong> are required to fit a <strong class="css-1vg6q84">perspective transform</strong>.</p><h3 id="acute32"><a href="#acute32" class="css-1r0pe6c">Acute32</a></h3><p class="css-1ftn47p">Acute32 uses circles as finders because they are distinct from the heavily cornered symbol set.</p><p class="css-1ftn47p">The advantage of using a circle is that, in general, it always transforms into an ellipse under any perspective distortion, making it relatively easy to detect.</p><p class="css-1ftn47p">The disadvantage is the <strong class="css-1vg6q84">lack of corners in circles</strong>. As a consequence, we need to put at least 4 finders on a symcode image.</p><h3 id="stage-2-fit-perspective-transform"><a href="#stage-2-fit-perspective-transform" class="css-1r0pe6c">Stage 2: Fit Perspective Transform</a></h3><p class="css-1ftn47p">We define the &quot;<strong class="css-1vg6q84">image space</strong>&quot; as the space of pixels on the <strong class="css-1vg6q84">input frame</strong>, and the &quot;<strong class="css-1vg6q84">object space</strong>&quot; as the space of pixels on the <strong class="css-1vg6q84">code image</strong> (whose boundary is predefined). An image space is simply the input frame image. An object space can either be generated using a code instance, or by rectifying the corresponding image space.</p><div><img alt="An example of image space (input frame)" style="display:block;margin-left:auto;margin-right:auto;width:800px;max-width:100%" src="/public/symcode/image_object_space_example.png"/><h4 style="text-align:center">An example of image space (input frame)</h4></div><p class="css-1ftn47p">In essence, this stage chooses the correct perspective transform to be used in the next stage.</p><p class="css-1ftn47p">Each perspective transform <strong class="css-1vg6q84">converts the image space into <em class="css-0">an</em> object space</strong> (but not necessarily the correct one) and <strong class="css-1vg6q84">is defined by (at least) 4 point pairs</strong> (source and destination points), where each pair consists of <strong class="css-1vg6q84">a point in the image space</strong> and <strong class="css-1vg6q84">the other one in the object space</strong>.</p><p class="css-1ftn47p">Since we have obtained a list of finder candidates from the previous stage, we can extract <strong class="css-1vg6q84"><em class="css-0">n</em> feature points in the image space</strong> from them. Matching the 4-permutations(or combinations) of them to the <strong class="css-1vg6q84">4 predefined feature points in the object space</strong> gives us at most <em class="css-0">n permute (or choose) 4 = k</em> perspective transforms (deriving the transform from point pairs is purely mathematics and is beyond the scope of this article).</p><p class="css-1ftn47p">It is indeed infeasible to apply each transformation and generate <em class="css-0">k</em> object spaces to choose the correct one. Therefore, we need to design some methods to evaluate each transform. The simplest way is to <strong class="css-1vg6q84">define some extra feature points in the object space as <em class="css-0">check points</em></strong>, which are <strong class="css-1vg6q84">re-projected to the image space</strong>, and <strong class="css-1vg6q84">check if the feature exists there</strong> (if the feature exists there, you are more confident that the transform is the correct one).</p><h3 id="acute32-1"><a href="#acute32-1" class="css-1r0pe6c">Acute32</a></h3><p class="css-1ftn47p">The re-projection method mentioned above hardly works on <code class="css-ueqitl">CircleFinder</code> because each circle finder only gives 1 feature point. The only way to obtain more feature points as check points is to add even more finders into the code image.</p><p class="css-1ftn47p"><code class="css-ueqitl">Acute32TransformFitter::evaluate_transform</code> takes each of the <em class="css-0">k</em> perspective transforms and calculates an error value.</p><p class="css-1ftn47p">We define 4 <strong class="css-1vg6q84">object check points</strong> as the top of the 4 circle finders in the object space. Re-projecting these 4 points to the image space, we obtain the <strong class="css-1vg6q84">image check points</strong> (<em class="css-0">i1</em> to <em class="css-0">i4</em>). Furthermore, we denote the <strong class="css-1vg6q84">centres of the circle finders</strong> in the <strong class="css-1vg6q84">image space</strong>, in the same order as the previously defined points, by <em class="css-0">c1</em> to <em class="css-0">c4</em> (illustrated below).</p><p class="css-1ftn47p">Our metric of evaluation relies on the most basic properties of vectors: <strong class="css-1vg6q84">direction and norm</strong>. Only 4 vectors interest us here: the vectors from the centres of finders to the image check points, and we denote them by <em class="css-0">v1</em> to <em class="css-0">v4</em> respectively.</p><div><img alt="Transform evaluation points and vectors: the 4 green vectors are v1 to v4" style="display:block;margin-left:auto;margin-right:auto;max-width:100%" src="/public/symcode/transform_evaluation.png"/><h4 style="text-align:center">Transform evaluation points and vectors: the 4 green vectors are v1 to v4</h4></div><p class="css-1ftn47p">Therefore, choosing the most correct transform is equivalent to <strong class="css-1vg6q84">minimizing the variances</strong> in the directions and norms of <em class="css-0">v1</em> to <em class="css-0">v4</em>.</p><h3 id="stage-3-recognize-symbols"><a href="#stage-3-recognize-symbols" class="css-1r0pe6c">Stage 3: Recognize Symbols</a></h3><p class="css-1ftn47p">In the previous stage, we have obtained a perspective transform which converts between the image and object spaces. Next, we&#x27;re going to rectify the input image into a code image, and recognize the symbols on it.</p><h4 id="rectify-the-image-space"><a href="#rectify-the-image-space" class="css-1r0pe6c">Rectify the image space</a></h4><p class="css-1ftn47p">Once we have a transform that we believe is correct, the object space can be obtained by applying it on the image space. We sample the image with bilinear interpolation.</p><h4 id="recognition"><a href="#recognition" class="css-1r0pe6c">Recognition</a></h4><div><img alt="Rectified image (code image in the correct object space)" style="display:block;margin-left:auto;margin-right:auto;max-width:100%" src="/public/symcode/object_space_example.png"/><h4 style="text-align:center">Rectified image (code image in the correct object space)</h4></div><p class="css-1ftn47p">Assuming the transform is correct, the coordinates of the symbols on the code image should be close to the <em class="css-0">anchors</em> we defined in the object space.</p><div><img alt="Recognition process marked by bounding boxes" style="display:block;margin-left:auto;margin-right:auto;max-width:100%" src="/public/symcode/recognition_demo.png"/><h4 style="text-align:center">Recognition process marked by bounding boxes</h4></div><p class="css-1ftn47p">The bounding boxes in blue are all clusters found on the code image. The boxes in red are the grouped clusters used to recognize each symbol.</p><p class="css-1ftn47p">Once we have the images, we can <strong class="css-1vg6q84">evaluate their traces</strong> and compare them with the ones in our symbol library, obtaining <strong class="css-1vg6q84">a small number of candidates</strong> for each symbol image. Each of these candidates is compared to the symbol image and the one with the <strong class="css-1vg6q84">lowest delta</strong> is the final predicted symbol.</p><p class="css-1ftn47p">Each symbol in the symbol set is mapped to a unique bit string, so each <code class="css-ueqitl">SymCode</code> instance concatenates a sequence of bit strings into a longer one. This long bit string is the information carried by the <code class="css-ueqitl">SymCode</code> instance.</p><h3 id="stage-4-decode-the-symcode"><a href="#stage-4-decode-the-symcode" class="css-1r0pe6c">Stage 4: Decode the SymCode</a></h3><p class="css-1ftn47p">This stage performs error detection (possibly correction) and extract the payload.</p><h3 id="acute32-2"><a href="#acute32-2" class="css-1r0pe6c">Acute32</a></h3><p class="css-1ftn47p">As there are 32 symbols in the set of Acute32, each symbol can encode 5 bits. Each <code class="css-ueqitl">SymCode</code> instance encodes <em class="css-0">25</em> raw bits, where <em class="css-0">20</em> bits are payload and <em class="css-0">5</em> bits are CRC checksum.</p><h2 id="conclusion"><a href="#conclusion" class="css-1r0pe6c">Conclusion</a></h2><p class="css-1ftn47p">We developed a theoretic as well as a programming framework for designing and implementing symbolic barcodes. The programming library is available as <code class="css-ueqitl">symcode</code>. For those who simply want to integrate SymCode into your existing application, please refer to the wasm distribution <code class="css-ueqitl">acute32</code> which is ready to use in any browser based Javascript projects.</p><h2 id="about-vision-cortex"><a href="#about-vision-cortex" class="css-1r0pe6c">About Vision Cortex</a></h2><blockquote class="css-16r6o5s"><p class="css-1ftn47p">&quot;Like everything metaphysical the harmony between thought and reality is to be found in the grammar of the language.&quot; - Ludwig Wittgenstein</p></blockquote><p class="css-1ftn47p">Communication is metaphysical. Communication between two humans is a language game. Communication between humans and machines in a purely visual manner is a complex language game. The syntax of the language is shapes, the grammar of the language is the spatial configuration, the semantics of the language is the meaning conveyed by these symbols.</p><p class="css-1ftn47p">This story is a manifest of the philosophy behind Vision Cortex, and a glimpse of the ongoing research and development by the Vision Cortex Research Group.</p><p class="css-1ftn47p">If you enjoyed the reading and appreciate our work, consider starring (on GitHub), discuss (on Reddit / GitHub), share (on Twitter / everywhere) and contribute.</p></div></div></main></div></div></div><div id="gatsby-announcer" style="position:absolute;top:0;width:1px;height:1px;padding:0;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border:0" aria-live="assertive" aria-atomic="true"></div></div><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/symcode-docs";/*]]>*/</script><script id="gatsby-chunk-mapping">/*<![CDATA[*/window.___chunkMapping={"polyfill":["/polyfill-acadad0340b9efb8cec1.js"],"app":["/app-22f19c56fe75b354f95d.js"],"component---src-impression-mdx":["/component---src-impression-mdx-b55ecb9846cfe6d2cf2d.js"],"component---src-index-mdx":["/component---src-index-mdx-39d5addb8abbe0d2329b.js"],"component---src-pages-404-js":["/component---src-pages-404-js-9c134c3c1761f19419a4.js"],"component---src-reversi-mdx":["/component---src-reversi-mdx-ea88f9697a8ba848802d.js"],"component---src-symcode-mdx":["/component---src-symcode-mdx-ab53366765a4d3ee24ae.js"],"component---src-vtracer-mdx":["/component---src-vtracer-mdx-eb117a97b4b1e4f1e0e8.js"]};/*]]>*/</script><script src="/polyfill-acadad0340b9efb8cec1.js" nomodule=""></script><script src="/component---src-symcode-mdx-ab53366765a4d3ee24ae.js" async=""></script><script src="/c8b6962d6148e584a9f22a767ed8f9cc94dfa8ff-cc82b785e04af3879186.js" async=""></script><script src="/798c9f31-55401554f16c5ec017b9.js" async=""></script><script src="/app-22f19c56fe75b354f95d.js" async=""></script><script src="/framework-bc0eb5446d96805b728a.js" async=""></script><script src="/styles-31f023f48facb69035d3.js" async=""></script><script src="/webpack-runtime-4ecf928c84a27444c6a9.js" async=""></script></body></html>